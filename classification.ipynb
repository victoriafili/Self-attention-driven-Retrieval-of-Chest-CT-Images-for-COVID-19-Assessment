{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f79fd2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import of basic libraries\n",
    "import tensorflow as tf\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from builtins import range, input\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "from tensorflow.keras.applications import DenseNet201\n",
    "from tensorflow.keras.applications.densenet import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939200c5",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c314cd",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c471658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "covid_path = \".\\\\kaggle\\\\COVID\"\n",
    "noncovid_path = \".\\\\kaggle\\\\non-COVID\"\n",
    "\n",
    "# Use 'glob' to retrieve all pathnames \n",
    "covid_files = glob(covid_path + '\\*')\n",
    "noncovid_files = glob(noncovid_path + '\\*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "452859e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the size to which images are to be resized\n",
    "IMAGE_SIZE = [224, 224]\n",
    "\n",
    "# Fetch images and Class labels from files\n",
    "covid_labels = []\n",
    "noncovid_labels = []\n",
    "\n",
    "covid_images=[]\n",
    "noncovid_images=[]\n",
    "\n",
    "# Covid\n",
    "for i in range(len(covid_files)):\n",
    "  image = cv2.imread(covid_files[i])             # read file \n",
    "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # arrange format as per kera\n",
    "  image = cv2.resize(image, IMAGE_SIZE)          # resize as per model\n",
    "  covid_images.append(image)                     # append image\n",
    "  covid_labels.append('CT_COVID')                # append class label\n",
    "\n",
    "# Non-Covid\n",
    "for i in range(len(noncovid_files)):\n",
    "  image = cv2.imread(noncovid_files[i])\n",
    "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "  image = cv2.resize(image, IMAGE_SIZE)\n",
    "  noncovid_images.append(image)\n",
    "  noncovid_labels.append('CT_NonCOVID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0196257e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization process - Convert to array and normalize to interval of [0,1] \n",
    "covid_images = np.array(covid_images) / 255\n",
    "noncovid_images = np.array(noncovid_images) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e01c8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test sets for both types of images\n",
    "covid_x_train, covid_x_test, covid_y_train, covid_y_test = train_test_split(\n",
    "    covid_images, ['CT_Covid' for file in covid_files], test_size=0.2)\n",
    "\n",
    "noncovid_x_train, noncovid_x_test, noncovid_y_train, noncovid_y_test = train_test_split(\n",
    "    noncovid_images, ['CT_NonCovid' for file in noncovid_files], test_size=0.2)\n",
    "\n",
    "# Merge sets for both types of images\n",
    "X_train = np.concatenate((noncovid_x_train, covid_x_train), axis=0)\n",
    "X_test = np.concatenate((noncovid_x_test, covid_x_test), axis=0)\n",
    "\n",
    "y_train = np.concatenate((noncovid_y_train, covid_y_train), axis=0)\n",
    "y_test = np.concatenate((noncovid_y_test, covid_y_test), axis=0)\n",
    "\n",
    "# Make labels into categories - either 0 or 1\n",
    "y_train = LabelBinarizer().fit_transform(y_train)\n",
    "y_train = to_categorical(y_train)\n",
    "\n",
    "y_test = LabelBinarizer().fit_transform(y_test)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "98f20abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a folder with the validation data - This code snippet was used only once\n",
    "import os\n",
    "import shutil\n",
    "for index, image in enumerate(X_train):\n",
    "  shutil.copyfile(image, os.path.join(r'.\\kaggle\\val_set_kaggle', os.path.basename(image)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fcde65",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# look at random images (covid and non-covid)\n",
    "def plot_images(images, title):\n",
    "    nrows, ncols = 5, 8\n",
    "    figsize = [10, 6]\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize, facecolor=(1, 1, 1))\n",
    "\n",
    "    for i, axi in enumerate(ax.flat):\n",
    "        axi.imshow(images[i])\n",
    "        axi.set_axis_off()\n",
    "\n",
    "    plt.suptitle(title, fontsize=24)\n",
    "    plt.tight_layout(pad=0.2, rect=[0, 0, 1, 0.9])\n",
    "    plt.show()\n",
    "    \n",
    "plot_images(covid_x_train, 'X_train')\n",
    "plot_images(covid_x_test, 'X_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a52c30f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find the amount of classes and calculate the train and test data\n",
    "unq_values_train, counts_train = np.unique(y_train, \n",
    "                                           return_counts=True \n",
    "                                          )\n",
    "unq_values_test, counts_test = np.unique(y_test, return_counts=True)\n",
    "\n",
    "# Graph for train data\n",
    "fig, axis = plt.subplots(nrows=1, ncols=2,\n",
    "                         sharey=True, \n",
    "                         figsize=(20,7))\n",
    "\n",
    "axis[0].bar(unq_values_train, \n",
    "            counts_train, \n",
    "            align=\"center\", \n",
    "            alpha=0.4 \n",
    "           )\n",
    "axis[0].set_xlabel(\"Class\") \n",
    "axis[0].set_ylabel(\"Frequency\") \n",
    "axis[0].set_title(\"Train Set\") \n",
    "\n",
    "# Graph for test data\n",
    "axis[1].bar(unq_values_test, counts_test, align=\"center\", alpha=0.4)\n",
    "axis[1].set_xlabel(\"Class\")\n",
    "axis[1].set_title(\"Test Set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3384e249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Model\n",
    "# Pre-trained DenseNet201\n",
    "densenet201Model = DenseNet201(weights=\"imagenet\", include_top=False,\n",
    "    input_tensor=Input(shape=(224, 224, 3)))\n",
    "\n",
    "outputs = densenet201Model.output\n",
    "\n",
    "# Add the extra layers\n",
    "outputs = GlobalAveragePooling2D()(outputs)\n",
    "outputs = Flatten(name=\"flatten\")(outputs)\n",
    "outputs = Dense(128, activation='relu')(outputs)\n",
    "outputs = Dropout(0.2)(outputs)\n",
    "outputs = Dense(64, activation='relu')(outputs)\n",
    "outputs = Dropout(0.3)(outputs)\n",
    "outputs = Dense(2, activation=\"sigmoid\")(outputs)\n",
    "\n",
    "model = Model(inputs=densenet201Model.input, outputs=outputs)\n",
    "\n",
    "for layer in densenet201Model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Define loss function, optimizer and metric\n",
    "model.compile(\n",
    "        loss='categorical_crossentropy', \n",
    "        optimizer='adam', \n",
    "        metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e52f8b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Augmentation\n",
    "# To train on images at different positions, angles, flips, e.t.c.\n",
    "train_aug = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f4ad4c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Î¤raining config:\n",
    "epochs = 500\n",
    "batch_size = 32\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_aug.flow(X_train, y_train, batch_size=batch_size),\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    validation_steps=len(X_test) / batch_size,\n",
    "                    steps_per_epoch=len(X_train) / batch_size,\n",
    "                    epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe1418a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model and Weights\n",
    "model.save('densenet201_ct.h5')\n",
    "model.save_weights('densenet201_weights_ct.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea8fdb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved model\n",
    "model = load_model('densenet201_ct.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18e7148",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Print the structure of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da4c227",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "y_pred = model.predict(X_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6a4084",
   "metadata": {},
   "source": [
    "### Make some predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4ec09f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction=y_pred[0:5]\n",
    "for index, probability in enumerate(prediction):\n",
    "  if probability[1] > 0.5:\n",
    "        plt.title('%.2f' % (probability[1]*100) + '% COVID')\n",
    "  else:\n",
    "        plt.title('%.2f' % ((1-probability[1])*100) + '% NonCOVID')\n",
    "  plt.imshow(X_test[index])\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0346824d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Binary classes\n",
    "y_pred_bin = np.argmax(y_pred, axis=1)\n",
    "y_test_bin = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb14072",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test_bin, y_pred_bin)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.title('ROC curve for our model')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e6bbda",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"Y_Actual\": y_test_bin, \n",
    "                  \"Y_Predicted\": y_pred_bin\n",
    "                  }\n",
    "                 )\n",
    "\n",
    "# Create the Confusion Matrix\n",
    "conf_mat = pd.crosstab(df[\"Y_Actual\"],     # actual classes\n",
    "                       df[\"Y_Predicted\"],  # predicted\n",
    "                       rownames=[\"Actual\"],\n",
    "                       colnames=[\"Predicted\"],\n",
    "                       margins=True\n",
    "                      )  \n",
    "\n",
    "print(f\"The confusion matrix of the classification is: \\n{conf_mat}\")\n",
    "print(\"-\"*100)\n",
    "\n",
    "conf_mat = conf_mat.drop(\"All\", axis=0) \n",
    "conf_mat = conf_mat.drop(\"All\", axis=1) \n",
    "\n",
    "# Create gragh\n",
    "f, axis = plt.subplots(nrows=1, ncols=1, figsize=(10, 6)) \n",
    "sns.heatmap(conf_mat, \n",
    "            annot=True, \n",
    "            fmt=\"d\", \n",
    "            cmap=\"YlGnBu\", # initialize color map (YlGnBu - > Yello Green Blue)\n",
    "            ax=axis\n",
    "            )\n",
    "axis.set_xlabel(\"\\nPredicted Class\")\n",
    "axis.set_ylabel(\"Actual Class\")\n",
    "axis.set_title(\"Confusion Matrix of the Classification\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e60e69",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Calculate the accuracy\n",
    "test_accuracy_nn = sklearn.metrics.accuracy_score(y_test_bin, y_pred_bin)\n",
    "\n",
    "print(\"The Accuracy of the Neural Network on the Test Data is :\", test_accuracy_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0571ec",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Print the classification report\n",
    "print(classification_report(y_test_bin, y_pred_bin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef81a355",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, axis = plt.subplots(nrows=1,ncols=2, figsize=(20,6))\n",
    "\n",
    "# Create the first gragh (Loss -> Cross-Entropy)\n",
    "axis[0].plot(history.epoch, history.history['loss']) # Cross Entropy - Training\n",
    "axis[0].plot(history.epoch, history.history['val_loss']) # Cross Entropy - Validation\n",
    "axis[0].set_xlabel(\"Epochs\") \n",
    "axis[0].set_ylabel(\"Value\") \n",
    "axis[0].legend([\"Loss\", \"Val_Loss\"]) \n",
    "axis[0].set_title(\"Training Process - Loss\") \n",
    "\n",
    "# Create the second gragh (Accuracy)\n",
    "axis[1].plot(history.epoch, history.history['accuracy'])\n",
    "axis[1].plot(history.epoch, history.history['val_accuracy'])\n",
    "axis[1].set_xlabel(\"Epochs\") \n",
    "axis[1].set_ylabel(\"Value\") \n",
    "axis[1].legend([\"Accuracy\", \"Val_Accuracy\"])\n",
    "axis[1].set_title(\"Training Process - Accuracy\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
